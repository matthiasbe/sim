\documentclass[9.5pt]{beamer}

\mode<presentation>
{
  \usetheme{Warsaw}       % or try default, Darmstadt, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{serif}    % or try default, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
} 

\usepackage[utf8]{inputenc} % accents 8 bits dans le fichier
\usepackage[T1]{fontenc}      % accents codés dans la fonte
\usepackage[french]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage[mode=buildnew]{standalone}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}


% Here's where the presentation starts, with the info for the title slide
\title[MPNA : MIS]{Présentation MPNA \\Méthode des itérations simultanées}
\author[\bsc{Beaupère} \& \bsc{Granger}]{Matthias \bsc{Beaupère} \& Pierre \bsc{Granger}}
\institute{M2 CHPS}
\date{\today}

\begin{document}
\setbeamercolor{captioncolor}{fg=white,bg=red!80!white}
\setbeamertemplate{caption}{%
\begin{beamercolorbox}[wd=0.8\linewidth, sep=.2ex]{captioncolor}\tiny\centering\insertcaption%
\end{beamercolorbox}%
}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Plan}
	\tableofcontents[hideallsubsections]
\end{frame}

\section{Introduction}
	\begin{frame}{Introduction}
		\begin{block}{Position du problème}
			\begin{itemize}
				\item Calcul de vp de grandes matrices creuses $\rightarrow$ matrice de Google.
				\item Seulement quelques vp dominantes.
				\item Algorithmes robustes.
				\item Algorithmes adaptés aux architectures massivement parallèles.
			\end{itemize}
		\end{block}
	\end{frame}

\section{Présentation de l'algorithme}
	\begin{frame}{La méthode des itérations simultanées}
		\begin{block}{Méthode de la puissance}
			\begin{itemize}
				\item Extraction de la vp dominante d'une matrice $A$.
				\item Multiplication répétée d'un vecteur initial par $A$.
				\item Convergence en $\left(\frac{\lambda_2}{\lambda_1}\right)^N$
			\end{itemize}
		\end{block}

		\begin{block}{Méthode des itérations simultanées}
			\begin{itemize}
				\item Espace invariant par $A$ de dim $k > 1$.
				\item Multiplication répétée du sous-espace par $A$.
				\item Orthonormalisation du sous-espace.
			\end{itemize}
		\end{block}
	\end{frame}

\section{Séquentiel}
	\subsection{Description}
		\begin{frame}{Données d'entrée}
			\begin{itemize}
				\item $M$ : taille du sous-espace de Krylov
				\item $k$ : nombre de vecteurs propres demandé
				\item $p$ : précision demandé
				\item $A$ : matrice de taille $N\times N$ donnée en entrée
				\item $N_{iter}$ : nombre d'itérations
			\end{itemize}
		\end{frame}
		\begin{frame}{Description de l'algorithme}
			\begin{algorithmic}
				\State $Q \gets rand()$
				\While {$i = 0 .. N_{iter}-1$ OU max(precisions) < p}
					\State $Z = AQ$
					\State Gram-Schmidt $Q$
					\State Projection $B = Z^tAZ$
					\State Décomposition de Schur $B = Y^tRY$
					\State Retour dans l'espace d'origine $Q = ZY$
					\State Calcul de la précision des vecteurs de $Q$
					\State Sélection des $k$ vecteurs propres
				\EndWhile
			\end{algorithmic}
		\end{frame}

	\subsection{Performances théoriques}
		\begin{frame}{Performances théoriques}
			\begin{tabular}{ l l }
				Produit $AQ$ & $O(N^2M)$ \\
				Gram-Schmidt & $O(NMlog(M))$ \\
				Projection & $O(N^2M)$ \\
				Décomposition de Schur & $O(1)$ \\
				Précision & $O(NM^2)$ \\
				Sélection & $O(1)$ \\
			\end{tabular}

			
			$$
			\fbox{$C^{tot} = O(N_{iter}N^2M)$}
			$$
		\end{frame}

	\subsection{Performances pratiques}
		\begin{frame}{Nombre d'itérations}
			\begin{figure}
				\centering
				\includegraphics[width = 0.7\linewidth]{../rapport/plots/tvsiter.pdf}
				\caption{Evolution du temps de calcul en fonction du nombre d'itérations. \label{fig:tvsiter}}
			\end{figure}
		\end{frame}

		\begin{frame}{Taille du sous-espace de Krylov $m$}
			\begin{figure}
				\centering
				\includegraphics[width = 0.7\linewidth]{../rapport/plots/tvsm.pdf}
				\caption{Evolution du temps de calcul en fonction de la taille du sous-espace de Krylov $m$. \label{fig:tvsm}}
			\end{figure}
		\end{frame}

		\begin{frame}{Taille de la matrice $M$}
			\begin{figure}
				\centering
				\includegraphics[width = 0.7\linewidth]{../rapport/plots/tvsM.pdf}
				\caption{Evolution du temps de calcul en fonction de la taille de la matrice $M$. \label{fig:tvsM}}
			\end{figure}
		\end{frame}

	\subsection{\'Etude de convergence}
		\begin{frame}{Influence de $m$}
			\begin{figure}
				\centering
				\includegraphics[width=0.8\linewidth, keepaspectratio]{../rapport/plots/Nvse-m_p6.pdf}
				\caption{Nombre d'itérations $N$ nécessaires pour faire converger $e$ valeurs propres pour différentes tailles de sous-espace de Krylov $m$ et une précision $p=\SI{e-6}{}$ \label{fig:Nvse-m_p6}}
			\end{figure}
		\end{frame}

		\begin{frame}{Influence de $p$}
			\begin{figure}
				\centering
				\includegraphics[width=0.8\linewidth, keepaspectratio]{../rapport/plots/Nvsp-m_e4.pdf}
				\caption{Nombre d'itérations $N$ nécessaires pour faire converger $e = 4$ valeurs propres pour différentes tailles de sous-espace de Krylov $m$ et une précision $p$ \label{fig:Nvsp-m_e4}}
			\end{figure}
		\end{frame}

	\subsection{Locking}
		\begin{frame}{Principe du locking}
			\begin{block}{Justificatons}
				\begin{itemize}
					\item Vitesses de convergence différentes des vp.
					\item Perte de temps.
					\item Instabilités numériques.
				\end{itemize}
			\end{block}

			\begin{exampleblock}{Le locking}
				\begin{itemize}
					\item On verrouille les vp lorsqu'ils ont convergé.
					\item On ne le multiplie par A.
					\item On diminue m.
					\item On l'utilise pour l'orthonormalisation.
				\end{itemize}
			\end{exampleblock}
		\end{frame}

		\begin{frame}{Performances du locking}
			\begin{figure}
				\centering
				\begin{columns}
					\column{0.5\linewidth}
					\centering
					\includegraphics[width=\linewidth, keepaspectratio]{../rapport/plots/wlock_e4_p8_m8.pdf}
					\caption{Avec locking\label{wlock_e4_p8_m8}}

					\column{0.5\linewidth}
					\centering
					\includegraphics[width=\linewidth, keepaspectratio]{../rapport/plots/wolock_e4_p8_m8.pdf}
					\caption{Sans locking\label{wolock_e4_p8_m8}}
				\end{columns}
				\caption{Précision au cours des itérations $N$ pour $e = 4$ valeurs propres pour une taille de sous-espace de Krylov $m=8$\label{fig:comp_locks}}
			\end{figure}
		\end{frame}

		\begin{frame}{Performances du locking}
			\begin{figure}
				\centering
				\includegraphics[width=0.8\linewidth, keepaspectratio]{../rapport/plots/Nvsp_complock.pdf}
				\caption{Nombre d'itérations $N$ nécessaires pour faire converger $e = 4$ valeurs propres pour différentes tailles de sous-espace de Krylov $m$ et une précision $p$ avec et sans utilisation du locking \label{fig:Nvsp_complock}}
			\end{figure}
		\end{frame}

\section{Multic\oe{}urs}
		\subsection{Description}
		\begin{frame}{Multic\oe{}urs}
			\begin{block}{Parallélisation OpenMP}
				\begin{itemize}
					\item On parallélise les produits matriciels dans l'espace d'origine
					\item Pragmas devant les boucles parallélisables
					\item Pas de pénalité de communication
					\item Performance : $C \rightarrow \frac{C}{N_\text{cores}}$
				\end{itemize}
			\end{block}
		\end{frame}

	\subsection{Performances pratiques}
		\begin{frame}{Multic\oe{}urs : performances pratiques}
			\begin{figure}
				\includegraphics[width=0.6\linewidth]{../rapport/plots/omp_perf.pdf}
				\caption{Nœud avec 8 cœurs hyperthreadés pour un calcul de 4 valeurs propres avec $m = 8$ à $p=\SI{e-8}{}$ \label{fig:omp_perf}}
			\end{figure}
			\centering
			Accélération x7 avec 8 coeurs physiques !
		\end{frame}

\section{Multin\oe{}uds}
	\subsection{Description}
		\begin{frame}{Multin\oe{}uds}
			\begin{block}{Parallélisation du calcul matriciel $C = AB$}
				\begin{itemize}
					\item \textbf{Rank 0} partage les matrices A et B aux autres processus
					\item \textbf{Tous} calculent une sous-matrice et renvoient le résultat
					\item \textbf{Rank 0} assemble C
				\end{itemize}
			\end{block}
		\end{frame}

	\subsection{Performances théoriques}
		\begin{frame}{Performances théoriques}
			On pose $N$ le nombre de processus
			\begin{block}{Temps de calcul processeur}
				Chaque c\oe{}ur calcul $\frac{1}{N}$ de la matrice C
				\center{Accélération $\times$ N}
			\end{block}
			\begin{block}{Communication pour un calcul $C = AB$}
				\begin{itemize}
					\item \textbf{Aller} : Toute la matrice B en broadcast
					\item \textbf{Aller} : $\frac{1}{\sqrt{N}}$ de la matrice A pour chaque processus
					\item \textbf{Retour} : $\frac{1}{N}$ de la matrice C
				\end{itemize}
				
			\end{block}
		\end{frame}

	\subsection{Performances pratiques}

		\begin{frame}{Multin\oe{}uds : performances pratiques}
			\begin{block}{Sur le supercalculateur poincare}
				\begin{tabular}{l l l l l l}
					taches	& noeuds & N & threads & M & temps(s)\\ \hline
					1 		& 1 & 1473 & 16 & 10 & 4.899005\\
					4 		& 4 & 1473 & 16 & 10 & 9.844218\\
					6 		& 1 & 1473 & 16 & 10 & 66.033455\\ \hline
					1 & 1 & 4929 & 16 & 10 & 29.481719\\
					4 & 4 & 4929 & 16 & 10 & 82.517647\\
				\end{tabular}
			\end{block}
		\end{frame}

\section{Conclusion}
	\begin{frame}{Conclusion}
		\begin{block}{Algorithme}
			\begin{itemize}
				\item Complexité pratique proche de la théorie.
				\item Importance du choix de $m$ en fonction des autres paramètres.
				\item Meilleure convergence et efficacité avec locking.
			\end{itemize}
		\end{block}

		\begin{block}{Parallélisation}
			\begin{itemize}
				\item Très bonne parallélisation intra-n\oe{}ud.
				\item Mauvaise scalabilité sur inter-n\oe{}ud $\rightarrow$ communications trop couteuses.
				\item Méthodes hybrides probablement mieux adaptées à l'inter-n\oe{}ud.
			\end{itemize}
		\end{block}
	\end{frame}

\end{document}
